{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-starting-again.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHgvm5lcySry"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from scipy.io import loadmat\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-KCQc0nykYn"
      },
      "source": [
        "!wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
        "!wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHe2wbM_ytL-"
      },
      "source": [
        "class SVHN_dataset(Dataset):\n",
        "\n",
        "    # def __init__(self, data,transform):\n",
        "    def __init__(self, data):  \n",
        "        # Transform data to Torch Tensors\n",
        "        self.images = torch.tensor(data['X']).permute([3,2,0,1])\n",
        "        self.labels = torch.tensor(data['y'])\n",
        "        self.size = self.labels.shape[0]\n",
        "\n",
        "        # replace label 10 with label 0\n",
        "        self.labels[self.labels==10] = 0\n",
        "        # convert to float and normalize images to 0..1 range\n",
        "        self.images = torch.FloatTensor(self.images/255.)\n",
        "        # self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Khoyr-yzG2"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(3,6,(5,5),padding=2,stride=1),\n",
        "        nn.BatchNorm2d(6),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(6,12,(3,3),padding=1,stride=1),\n",
        "        nn.BatchNorm2d(12),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Conv2d(12,24,(3,3),padding=1,stride=1),\n",
        "        nn.BatchNorm2d(24),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.fc1 = nn.Linear(24*4*4, 10)\n",
        "    # self.fc1 = nn.Linear(in_features=24*4*4, out_features=120)\n",
        "    # self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    # self.out = nn.Linear(in_features=60, out_features=10)\n",
        "  \n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    # print(out.shape)\n",
        "\n",
        "    out = self.layer2(out)\n",
        "    # print(out.shape)\n",
        "\n",
        "    out = self.layer3(out)\n",
        "    # print(out.shape)\n",
        "\n",
        "    out = out.reshape(-1, 24 * 4 * 4)\n",
        "    out = self.fc1(out)\n",
        "    # out = F.relu(out)\n",
        "\n",
        "    # out = self.fc2(out)\n",
        "    # out = F.relu(out)\n",
        "\n",
        "    # out = self.out(out)\n",
        "    # out = F.softmax(out)\n",
        "    # print(out.shape)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs8awPv800kL"
      },
      "source": [
        "# initialize weights of CNN layers\n",
        "def init_weights(m):\n",
        "  mean = 0.0\n",
        "  std = 0.001\n",
        "  if isinstance(m, nn.Conv2d):\n",
        "    m.weight.data.normal_(mean,std)\n",
        "    if m.bias is not None:\n",
        "      nn.init.constant_(m.bias.data, 0)\n",
        "  elif isinstance(m, nn.BatchNorm2d):\n",
        "    m.weight.data.normal_(mean,std)\n",
        "    if m.bias is not None:\n",
        "      nn.init.constant_(m.bias.data, 0)\n",
        "  elif isinstance(m, nn.Linear):\n",
        "    m.weight.data.normal_(mean,std)\n",
        "    if m.bias is not None:\n",
        "      nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LtrStvF011h"
      },
      "source": [
        "# transform = transforms.Compose(\n",
        "#       [\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "#         ]\n",
        "#     )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dHaa_bM1GHt"
      },
      "source": [
        "train = loadmat('train_32x32.mat')\n",
        "test = loadmat('test_32x32.mat')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNDsNpsi1GzJ",
        "outputId": "97c539e7-9bf5-440d-e196-2ae00bc30497"
      },
      "source": [
        "print(train['X'].shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 3, 73257)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9u7Y_OT1L_M"
      },
      "source": [
        "# train_SVHNdataset = SVHN_dataset(data = train, transform = transform)\n",
        "# test_SVHNdataset = SVHN_dataset(data = test, transform = transform)\n",
        "train_SVHNdataset = SVHN_dataset(data = train)\n",
        "test_SVHNdataset = SVHN_dataset(data = test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZhptBih1d-M"
      },
      "source": [
        "params = {'batch_size': 512,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 2,\n",
        "          'pin_memory':True}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bpHge941gyd"
      },
      "source": [
        "trainSVHN_loader = DataLoader(train_SVHNdataset, **params)\n",
        "testSVHN_loader = DataLoader(test_SVHNdataset, **params)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB3qSLSk1mis",
        "outputId": "36e79634-fdc7-4df0-e827-a3298180c2e2"
      },
      "source": [
        "model = CNN()\n",
        "model.apply(init_weights)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else cpu)\n",
        "print(device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8iPAFY21uYp",
        "outputId": "0b5e206d-0b1a-4c42-f239-9d504208e97f"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc1): Linear(in_features=384, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4HM2oKO1y1o"
      },
      "source": [
        "learning_rate = 0.001\n",
        "lossfunc = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSXgq45N13wC",
        "outputId": "e143729e-ab58-496b-b948-e3efbdf163aa"
      },
      "source": [
        "num_epochs = 50\n",
        "# loss_values = list()\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    training_loss = 0\n",
        "    model.train()\n",
        "    for X_train, y_train in trainSVHN_loader:\n",
        "      # Transfer to GPU\n",
        "      X_train_tensor = torch.tensor(X_train, dtype = torch.float)\n",
        "      y_train_tensor = torch.tensor(y_train, dtype = torch.long)\n",
        "\n",
        "      images, labels = Variable(X_train_tensor).to(device), Variable(y_train_tensor).to(device)\n",
        "\n",
        "      # model computation\n",
        "      outputs = model(images)\n",
        "      target = labels.squeeze()\n",
        "      loss = lossfunc(outputs, target)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      training_loss += loss.item()\n",
        "    training_loss /= len(trainSVHN_loader)\n",
        "    print('Epoch -',epoch, 'training loss - ', training_loss)\n",
        "print('Finished Training')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch - 0 training loss -  2.2212345004081726\n",
            "Epoch - 1 training loss -  1.4563380016220941\n",
            "Epoch - 2 training loss -  0.8480565663841035\n",
            "Epoch - 3 training loss -  0.7231536867717901\n",
            "Epoch - 4 training loss -  0.6686514860226048\n",
            "Epoch - 5 training loss -  0.6316460789077811\n",
            "Epoch - 6 training loss -  0.6097860530846648\n",
            "Epoch - 7 training loss -  0.5863562636077404\n",
            "Epoch - 8 training loss -  0.5715276704480251\n",
            "Epoch - 9 training loss -  0.5594563221351968\n",
            "Epoch - 10 training loss -  0.5470230927069982\n",
            "Epoch - 11 training loss -  0.540867736356126\n",
            "Epoch - 12 training loss -  0.5263313996709056\n",
            "Epoch - 13 training loss -  0.5206435558696588\n",
            "Epoch - 14 training loss -  0.5153970008509027\n",
            "Epoch - 15 training loss -  0.5099788310213221\n",
            "Epoch - 16 training loss -  0.5037676617503166\n",
            "Epoch - 17 training loss -  0.496163013494677\n",
            "Epoch - 18 training loss -  0.4925959629731046\n",
            "Epoch - 19 training loss -  0.4885523182650407\n",
            "Epoch - 20 training loss -  0.48774432287447983\n",
            "Epoch - 21 training loss -  0.48288203092912835\n",
            "Epoch - 22 training loss -  0.47748292547961074\n",
            "Epoch - 23 training loss -  0.47386355822285015\n",
            "Epoch - 24 training loss -  0.47277347184717655\n",
            "Epoch - 25 training loss -  0.4674752313229773\n",
            "Epoch - 26 training loss -  0.46604217237068546\n",
            "Epoch - 27 training loss -  0.46477278301285374\n",
            "Epoch - 28 training loss -  0.45921537569827503\n",
            "Epoch - 29 training loss -  0.46015198135541546\n",
            "Epoch - 30 training loss -  0.4559019801931249\n",
            "Epoch - 31 training loss -  0.4550610890405046\n",
            "Epoch - 32 training loss -  0.4533716042836507\n",
            "Epoch - 33 training loss -  0.45059002263264525\n",
            "Epoch - 34 training loss -  0.4497480899509456\n",
            "Epoch - 35 training loss -  0.4490899294614792\n",
            "Epoch - 36 training loss -  0.4448923199541039\n",
            "Epoch - 37 training loss -  0.44539240064720315\n",
            "Epoch - 38 training loss -  0.44560433530973065\n",
            "Epoch - 39 training loss -  0.44220740844806034\n",
            "Epoch - 40 training loss -  0.44054659435318577\n",
            "Epoch - 41 training loss -  0.43748721790810424\n",
            "Epoch - 42 training loss -  0.4380544407500161\n",
            "Epoch - 43 training loss -  0.4341880445265108\n",
            "Epoch - 44 training loss -  0.4311801381409168\n",
            "Epoch - 45 training loss -  0.43262142729428077\n",
            "Epoch - 46 training loss -  0.43203905824985767\n",
            "Epoch - 47 training loss -  0.43087544437083936\n",
            "Epoch - 48 training loss -  0.4252964752829737\n",
            "Epoch - 49 training loss -  0.43030642883645165\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbUrHVfp19ES",
        "outputId": "2dd733be-e08b-4ebf-e60d-1cb5c82f87e9"
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  batches = 0\n",
        "  for X_test, y_test in testSVHN_loader:\n",
        "      X_test_tensor = torch.tensor(X_test, dtype = torch.float)\n",
        "      y_test_tensor = torch.tensor(y_test, dtype = torch.long)\n",
        "      images, labels = Variable(X_test_tensor).to(device), Variable(y_test_tensor).to(device)\n",
        "      outputs = model(images)\n",
        "      target = labels.squeeze()\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      batches += labels.size(0)\n",
        "      correct += (predicted == target).sum().item()\n",
        "\n",
        "  print('Test Accuracy of the model: {} %'.format(100 * correct / batches))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model: 84.53441917639827 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}