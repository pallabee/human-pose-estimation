{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-starting-again.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHgvm5lcySry"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from scipy.io import loadmat\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-KCQc0nykYn",
        "outputId": "b559c355-58de-48c8-fce1-c64432b6c75c"
      },
      "source": [
        "!wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
        "!wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-14 08:48:21--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182040794 (174M) [text/plain]\n",
            "Saving to: ‘train_32x32.mat’\n",
            "\n",
            "train_32x32.mat     100%[===================>] 173.61M  22.7MB/s    in 7.9s    \n",
            "\n",
            "2021-08-14 08:48:29 (21.9 MB/s) - ‘train_32x32.mat’ saved [182040794/182040794]\n",
            "\n",
            "--2021-08-14 08:48:29--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64275384 (61M) [text/plain]\n",
            "Saving to: ‘test_32x32.mat’\n",
            "\n",
            "test_32x32.mat      100%[===================>]  61.30M  20.2MB/s    in 3.0s    \n",
            "\n",
            "2021-08-14 08:48:32 (20.2 MB/s) - ‘test_32x32.mat’ saved [64275384/64275384]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHe2wbM_ytL-"
      },
      "source": [
        "class SVHN_dataset(Dataset):\n",
        "\n",
        "    def __init__(self, data,transform):\n",
        "        # Transform data to Torch Tensors\n",
        "        self.images = torch.tensor(data['X']).permute([3,2,0,1])\n",
        "        self.labels = torch.tensor(data['y'])\n",
        "        self.size = self.labels.shape[0]\n",
        "\n",
        "        # replace label 10 with label 0\n",
        "        self.labels[self.labels==10] = 0\n",
        "        # convert to float and normalize images to 0..1 range\n",
        "        self.images = torch.FloatTensor(self.images/255.)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Khoyr-yzG2"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(3,6,(5,5),padding=2,stride=1),\n",
        "        nn.BatchNorm2d(6),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(6,12,(3,3),padding=1,stride=1),\n",
        "        nn.BatchNorm2d(12),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Conv2d(12,24,(3,3),padding=1,stride=1),\n",
        "        nn.BatchNorm2d(24),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.fc1 = nn.Linear(24*4*4, 10)\n",
        "    # self.fc1 = nn.Linear(in_features=24*4*4, out_features=120)\n",
        "    # self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    # self.out = nn.Linear(in_features=60, out_features=10)\n",
        "  \n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    # print(out.shape)\n",
        "\n",
        "    out = self.layer2(out)\n",
        "    # print(out.shape)\n",
        "\n",
        "    out = self.layer3(out)\n",
        "    # print(out.shape)\n",
        "\n",
        "    out = out.reshape(-1, 24 * 4 * 4)\n",
        "    out = self.fc1(out)\n",
        "    # out = F.relu(out)\n",
        "\n",
        "    # out = self.fc2(out)\n",
        "    # out = F.relu(out)\n",
        "\n",
        "    # out = self.out(out)\n",
        "    # out = F.softmax(out)\n",
        "    # print(out.shape)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs8awPv800kL"
      },
      "source": [
        "# initialize weights of CNN layers\n",
        "def init_weights(m):\n",
        "  mean = 0.0\n",
        "  std = 0.001\n",
        "  if isinstance(m, nn.Conv2d):\n",
        "    m.weight.data.normal_(mean,std)\n",
        "    if m.bias is not None:\n",
        "      nn.init.constant_(m.bias.data, 0)\n",
        "  elif isinstance(m, nn.BatchNorm2d):\n",
        "    m.weight.data.normal_(mean,std)\n",
        "    if m.bias is not None:\n",
        "      nn.init.constant_(m.bias.data, 0)\n",
        "  elif isinstance(m, nn.Linear):\n",
        "    m.weight.data.normal_(mean,std)\n",
        "    if m.bias is not None:\n",
        "      nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LtrStvF011h"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "      [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dHaa_bM1GHt"
      },
      "source": [
        "train = loadmat('train_32x32.mat')\n",
        "test = loadmat('test_32x32.mat')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNDsNpsi1GzJ",
        "outputId": "6e856a77-f39e-49ec-96a2-590e5ae9fd20"
      },
      "source": [
        "print(train['X'].shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 3, 73257)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9u7Y_OT1L_M"
      },
      "source": [
        "train_SVHNdataset = SVHN_dataset(data = train, transform = transform)\n",
        "test_SVHNdataset = SVHN_dataset(data = test, transform = transform)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZhptBih1d-M"
      },
      "source": [
        "params = {'batch_size': 512,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 1,\n",
        "          'pin_memory':True}"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bpHge941gyd"
      },
      "source": [
        "trainSVHN_loader = DataLoader(train_SVHNdataset, **params)\n",
        "testSVHN_loader = DataLoader(test_SVHNdataset, **params)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB3qSLSk1mis",
        "outputId": "84dce94b-f84c-4334-ba72-8840520f1bd9"
      },
      "source": [
        "model = CNN()\n",
        "model.apply(init_weights)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else cpu)\n",
        "print(device)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8iPAFY21uYp",
        "outputId": "c756d43f-6ad5-4b7e-c534-47c0207d24cf"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc1): Linear(in_features=384, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4HM2oKO1y1o"
      },
      "source": [
        "learning_rate = 0.001\n",
        "lossfunc = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSXgq45N13wC",
        "outputId": "77816d09-8b35-471d-b874-57cb3ab3dab5"
      },
      "source": [
        "num_epochs = 50\n",
        "# loss_values = list()\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    training_loss = 0\n",
        "    model.train()\n",
        "    for X_train, y_train in trainSVHN_loader:\n",
        "      # Transfer to GPU\n",
        "      X_train_tensor = torch.tensor(X_train, dtype = torch.float)\n",
        "      y_train_tensor = torch.tensor(y_train, dtype = torch.long)\n",
        "\n",
        "      images, labels = Variable(X_train_tensor).to(device), Variable(y_train_tensor).to(device)\n",
        "\n",
        "      # model computation\n",
        "      outputs = model(images)\n",
        "      target = labels.squeeze()\n",
        "      loss = lossfunc(outputs, target)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      training_loss += loss.item()\n",
        "    training_loss /= len(trainSVHN_loader)\n",
        "    print('Epoch -',epoch, 'training loss - ', training_loss)\n",
        "print('Finished Training')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch - 0 training loss -  2.1968663185834885\n",
            "Epoch - 1 training loss -  1.5675868069132168\n",
            "Epoch - 2 training loss -  0.96022435484661\n",
            "Epoch - 3 training loss -  0.7437088820669386\n",
            "Epoch - 4 training loss -  0.6551268251819743\n",
            "Epoch - 5 training loss -  0.6099807479315333\n",
            "Epoch - 6 training loss -  0.5810441718333297\n",
            "Epoch - 7 training loss -  0.5610017234252559\n",
            "Epoch - 8 training loss -  0.54525836598542\n",
            "Epoch - 9 training loss -  0.5331482065634595\n",
            "Epoch - 10 training loss -  0.5232643640289704\n",
            "Epoch - 11 training loss -  0.5158280705412229\n",
            "Epoch - 12 training loss -  0.5078822608209319\n",
            "Epoch - 13 training loss -  0.49887703731656075\n",
            "Epoch - 14 training loss -  0.4910759071095122\n",
            "Epoch - 15 training loss -  0.48601005950735676\n",
            "Epoch - 16 training loss -  0.48279699000219506\n",
            "Epoch - 17 training loss -  0.484755191538069\n",
            "Epoch - 18 training loss -  0.4785199782086743\n",
            "Epoch - 19 training loss -  0.47489754545191926\n",
            "Epoch - 20 training loss -  0.4710580040183332\n",
            "Epoch - 21 training loss -  0.4616852934575743\n",
            "Epoch - 22 training loss -  0.4607395782238907\n",
            "Epoch - 23 training loss -  0.4571729521784518\n",
            "Epoch - 24 training loss -  0.45257070619199014\n",
            "Epoch - 25 training loss -  0.4579274132847786\n",
            "Epoch - 26 training loss -  0.4480784696837266\n",
            "Epoch - 27 training loss -  0.447958438967665\n",
            "Epoch - 28 training loss -  0.44697429715759224\n",
            "Epoch - 29 training loss -  0.4466191563341353\n",
            "Epoch - 30 training loss -  0.4408769966620538\n",
            "Epoch - 31 training loss -  0.44277328521841103\n",
            "Epoch - 32 training loss -  0.4384830317770441\n",
            "Epoch - 33 training loss -  0.43494329787790775\n",
            "Epoch - 34 training loss -  0.4347754952808221\n",
            "Epoch - 35 training loss -  0.43224461004137993\n",
            "Epoch - 36 training loss -  0.43230610113177037\n",
            "Epoch - 37 training loss -  0.4294981141057279\n",
            "Epoch - 38 training loss -  0.4251567998694049\n",
            "Epoch - 39 training loss -  0.42696941685345435\n",
            "Epoch - 40 training loss -  0.42601789513395893\n",
            "Epoch - 41 training loss -  0.42514428454968667\n",
            "Epoch - 42 training loss -  0.4231018761379851\n",
            "Epoch - 43 training loss -  0.4237109426822927\n",
            "Epoch - 44 training loss -  0.41868028706974453\n",
            "Epoch - 45 training loss -  0.41793768687380684\n",
            "Epoch - 46 training loss -  0.4155744200365411\n",
            "Epoch - 47 training loss -  0.4153836342609591\n",
            "Epoch - 48 training loss -  0.41502523463633323\n",
            "Epoch - 49 training loss -  0.41600931704872185\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbUrHVfp19ES",
        "outputId": "ca6c5f2e-da84-4f17-be1e-1f9229907787"
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  batches = 0\n",
        "  for X_test, y_test in testSVHN_loader:\n",
        "      X_test_tensor = torch.tensor(X_test, dtype = torch.float)\n",
        "      y_test_tensor = torch.tensor(y_test, dtype = torch.long)\n",
        "      images, labels = Variable(X_test_tensor).to(device), Variable(y_test_tensor).to(device)\n",
        "      outputs = model(images)\n",
        "      target = labels.squeeze()\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      batches += labels.size(0)\n",
        "      correct += (predicted == target).sum().item()\n",
        "\n",
        "  print('Test Accuracy of the model: {} %'.format(100 * correct / batches))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model: 81.43438844499079 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}